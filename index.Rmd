---
title: Time for public pharma?
subtitle: Supplementary material
author: Christopher Okhravi
date: 2019
output:
  html_document:
    number_sections: true
    toc: true
    toc_float:
      collapsed: false
    theme: default
    highlight: haddock
---


# Introduction
This document contains the full analysis that underpins the paper paper "Time for public pharma?".
This is a monte carlo simulation that explores direct versus indirect funding of antibiotics research and development (R&D).
Direct funding is here used to mean that a benefactor pays for antibiotics R&D at cost.
Indirect funding is here used to mean that a benefactor issues non-dilutive prizes to whoever completes a particular phase, with the intent of incentivizing private developers to undertake said and prior phases.
This analysis estimates which of the two, ceteris paribus, is cheaper for the benefactor.

## How to compile this document
If you're reading this in an html format then the document is already compiled.
You can compile the Rmd file like this:

```bash
Rscript -e "library(rmarkdown); render('index.Rmd')"
```

Note: While most of the code that is used to perform the analysis is included in the rendered (i.e. output) document, some is not.
If you need further details, please consult the source code used to generate the output document.


# Input data
We begin by setting `N` which will dictate the number of project samples that we'll draw from each dataset.
Meaning that if one considers all the data sets at once then the number of random projects drawn is in total `N` times the number of data sets considered.
In other words, `N` is the number of random samples that we'll draw from a stochastic representation of a hypothetical antibiotic R&D project.
The distribution of the stochastic project depends on the data set we're using, and in a simple attempt to avoid drawing data set specific conclusions, we'll look at multiple data sets.

```{r, set-n}
N = 500
```

```{r, basics, include=FALSE}
# Dependencies
library(knitr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(triangle)
library(scales)

# Cache code chunks
knitr::opts_chunk$set(cache=TRUE, collapse=TRUE)

# Set seed for reproducibility
set.seed(1)

# NOTE: I can't figure out how to sample from multiple triangular distributions
# at the same time using rtriangle, so here's my sloppy quickfix implementation.
# Usage is the same as rtriangle, but you can pass vectors in mins, maxs and mids.
rtriangle2 <- function(n, mins, maxs, mids) {
  xs <- c()
  while (length(xs) < n)
    for (x in 1:length(mins))
      xs <- c(xs, rtriangle(1, mins[x], maxs[x], mids[x]))
  xs
}

# The phases we'll be working with
DEVELOPMENT_PHASES <- c('PC','P1','P2','P3','P4')
MARKET_PHASES <- paste('M', 1:10, sep='')
PHASES <- c(DEVELOPMENT_PHASES, MARKET_PHASES)
```

The data in this analysis stem from two publications, Sertkaya et. al (2014) and DRIVE-AB (2018).
The latter considers only a single hypothetical antibiotic, while the former considers six hypothetical antibiotics targeting different indications.
Our analysis is thus applied to seven data sets stemming from two publications.
Disclaimer: The data in DRIVE-AB (2018) is heavily based on Sertkaya et. al (2014) and is thus not an independently collected dataset.
Nevertheless the spread of data across the seven datasets will hopefully convince the reader that our conclusions hold over a wide range of input data variation.



## Sertkaya distribution

The following is an approximation of the data used by Sertkaya et. al (2014) as a few of their assumptions are not reconcilable with our modeling choices.
Sertkaya et. al (2014) differentiates between antibiotics on the basis of target indication.
In this analysis we treat the data for each target indication a separate dataset.

```{r, dist-sertkaya, echo=FALSE}
INDICATIONS <- c('ABOM', 'ABSSSI', 'CABP', 'CIAI', 'CUTI', 'HABP/VABP')

sertkaya2014_phase_dist <-
  rbind(data.frame(indication = INDICATIONS,
                   phase = 'PC',
                   time_min = 52,
                   time_mid = 66,
                   time_max = 72,
                   cost_min = 19,
                   cost_mid = 21.1,
                   cost_max = 23.2,
                   prob_min = 17.5,
                   prob_mid = 35.2,
                   prob_max = 69
                   ),
        data.frame(indication = INDICATIONS,
                   phase = 'P1',
                   time_min = 9,
                   time_mid = 10.5,
                   time_max = 21.6,
                   cost_min = 7.3,
                   cost_mid = 9.7,
                   cost_max = 12,
                   prob_min = 25,
                   prob_mid = 33,
                   prob_max = 83.7
                   ),
        data.frame(indication = INDICATIONS,
                   phase = 'P2',
                   time_min = c(12, 9, 12, 10, 10, 16),
                   time_mid = c(15, 10, 15, 11, 11, 18),
                   time_max = 30,
                   cost_min = c(7.4, 7.12, 7.28, 7.68, 7.28, 12.48),
                   cost_mid = c(9.2, 8.9, 9.1, 9.6, 9.1, 15.6),
                   cost_max = c(11, 10.68, 10.92, 11.52, 10.92, 18.72),
                   prob_min = 34,
                   prob_mid = 50,
                   prob_max = 74
                   ),
        data.frame(indication = INDICATIONS,
                   phase = 'P3',
                   time_min = c(20, 10, 10, 17, 17, 35),
                   time_mid = c(24, 12.5, 12.5, 21.5, 21.5, 39),
                   time_max = 47,
                   cost_min = c(33.36, 26.88, 31.04, 40.48, 35.04, 81.12),
                   cost_mid = c(41.7, 33.6, 38.8, 50.6, 43.8, 101.4),
                   cost_max = c(50.04, 40.32, 46.56, 60.72, 52.56, 121.68),
                   prob_min = 31.4,
                   prob_mid = 67,
                   prob_max = 78.6
                   ),
        data.frame(indication = INDICATIONS,
                   phase = 'P4',
                   time_min = 6,
                   time_mid = 9,
                   time_max = 12.5,
                   cost_min = 1.9588, # NDA/BLA submission cost
                   cost_mid = 1.9588, # NDA/BLA submission cost
                   cost_max = 1.9588, # NDA/BLA submission cost,
                   prob_min = 83,
                   prob_mid = 85,
                   prob_max = 99
                   )
        ) %>% arrange(phase, indication)

sertkaya2014_market_size_dist <-
  data.frame(indication = INDICATIONS,
             min = c(2720, 3070, 2290, 2530, 5760, 1780),
             max = 9230)

sertkaya2014_market_share_dist <-
  data.frame(year = 1:10,
             min = c(0.05, 0.87, 1.57, 2.57, 3.92, 5.79, 7.52, 8.52, 10.10, 12.27),
             max = c(0.11, 1.91, 3.47, 5.68, 8.64, 12.77, 16.59, 18.80, 22.30, 27.08))
```

In the tables below, time is expressed in months, cost and revenues in million USD, and probabilities and market shares in percentage.

```{r, print-sertkaya-dist, echo=FALSE}
kable(sertkaya2014_phase_dist, caption='sertkaya2014_phase_dist')
kable(sertkaya2014_market_size_dist, caption='sertkaya2014_market_size_dist')
kable(sertkaya2014_market_share_dist, caption='sertkaya2014_market_share_dist')
```

Sertkaya et. al (2014) also consider costs for a few additional (1) supply chain activities, (2) non-clinical work, and (3) post-approval studies as listed below.
The costs are spread across various phases as indicated by the fractions under the corresponding phase columns.
These figures and fractions stem from Table 9, section 3.2.7, and section 3.2.8 of Sertkaya et. al (2014) respectively.
Sertkaya et. al (2014) repoert that the cost of post-approval studies may last up to three years into the market.
As such we assume that the cost is evenly distributed over three years.

```{r, sertkaya-additional-dist, echo=FALSE}
activity <-
  c('Sample preparation for animal/human studies',
    'Process research/development/design',
    'Plant design',
    'Plant build',
    'Non-clinical work',
    'Post-approval studies')
sertkaya2014_additional_dist <-
  data.frame(activity,
             min = c(2.4, 18.7, 10.7, 69.6, 3.4, 8),
             mid = c(2.7, 26.8, 13.4, 83,   3.7, 10),
             max = c(2.9, 34.8, 16.1, 96.3, 4,   12),
             PC = 0,
             P1 = c(1/3, 0.5, 0,    0, 0,   0),
             P2 = c(1/3, 0.5, 0,    0, 1/3, 0),
             P3 = c(1/3, 0,   0.75, 0, 1/3, 0),
             P4 = c(0,   0,   0.25, 1, 1/3, 0),
             M1 = c(0,   0,   0,    0, 0,   1/3),
             M2 = c(0,   0,   0,    0, 0,   1/3),
             M3 = c(0,   0,   0,    0, 0,   1/3)
  )


sertkaya2014_additional_dist %>%
  mutate(P1 = round(P1, 2) * 100,
         P2 = round(P2, 2) * 100,
         P3 = round(P3, 2) * 100,
         P4 = round(P4, 2) * 100,
         M1 = round(M1, 2) * 100,
         M2 = round(M2, 2) * 100,
         M3 = round(M3, 2) * 100) %>%
  kable(caption='sertkaya2014_additional_dist (million usd and rounded percentages)')
```

Finally, Sertkaya et. al (2014) presents their assumed discount rates in section 3.2.1 of their report, and we employ the same, as per the table below.

```{r, sertkaya-discount-rate-dist, echo=FALSE}
sertkaya2014_discount_rate_dist <-
  data.frame(min = 0.09, mid = 0.11, max = 0.24)

kable(sertkaya2014_discount_rate_dist, caption='sertkaya2014_discount_rate_dist')
```


## Sertkaya sample
We first sample development data from the Sertkaya distributions.

```{r, sample-sertkaya-dev}
# Ensure expected order of rows in distribution before sampling
dist <- sertkaya2014_phase_dist %>%
  arrange(indication, phase)

# Convenience aliases
num_phases <- length(DEVELOPMENT_PHASES)
num_indications <- length(INDICATIONS)

# Build data frame
sertkaya2014_dev <- data.frame(
  subject = rep(1:(N * num_indications), each = num_phases),
  src = dist$indication,
  phase = dist$phase,
  time = rtriangle2(N * num_phases * num_indications, dist$time_min, dist$time_max, dist$time_mid),
  cost = rtriangle2(N * num_phases * num_indications, dist$cost_min, dist$cost_max, dist$cost_mid),
  prob = rtriangle2(N * num_phases * num_indications, dist$prob_min, dist$prob_max, dist$prob_mid),
  sales = 0)
```

We then sample the additional supply chain activity costs data,
distribute the samples across the phases according to their corresponding fractions,
and then sum up the additional costs per phase for every subject.
From this point onwards it is therefore impossible to distinguish e.g. non-clinical work costs from sample preparation costs.

```{r, sample-sertkaya-additional}
sertkaya2014_subjects <- unique(sertkaya2014_dev$subject)
sertkaya2014_additional <-

  # Replicate distributions N times
  do.call('rbind', replicate(N * num_indications, sertkaya2014_additional_dist, simplify=FALSE)) %>%

  # Add subject identifiers
  mutate(subject = rep(sertkaya2014_subjects, each = nrow(sertkaya2014_additional_dist))) %>%

  # Sample distributions
  mutate(tot_cost = rtriangle2(n(), min, max, mid)) %>%

  # Wide to long
  select(-activity, -min, -max, -mid) %>%
  gather(phase, fraction, -subject, -tot_cost) %>%

  # Compute actual cost in phase
  mutate(cost = tot_cost * fraction) %>%

  # Sum up costs per phase
  group_by(subject, phase) %>%
  summarize(add_cost = sum(cost))
```

We then sample market data from the Sertkaya distributions.

```{r, sample-sertkaya-market}
num_years <- length(unique(sertkaya2014_market_share_dist$year))
share_dist <- sertkaya2014_market_share_dist
size_dist <- sertkaya2014_market_size_dist

# Merge market share dist and market size dist to simplify sampling
dist <-
  data.frame(indication = size_dist$indication,
             size_min = size_dist$min,
             size_max = size_dist$max,
             year = rep(share_dist$year, each = num_indications),
             share_min = rep(share_dist$min, each = num_indications),
             share_max = rep(share_dist$max, each = num_indications)) %>%

  # Ensure expected order of rows in distribution before sampling
  arrange(indication, year)

# Build data frame
sertkaya2014_market <-
  data.frame(
    subject = rep(1:(N * num_indications), each = num_years),
    src = dist$indication,
    # Deliberately not using MARKET_PHASES to ensure that I'm grabbing the rows
    # in the correct order.
    phase = paste('M', dist$year, sep=''),
    time = 12,  # months
    cost = 0,   # million usd
    prob = 100, # percentage
    share = runif(N * num_indications * num_years, dist$share_min, dist$share_max),
    size = runif(N * num_indications * num_years, dist$size_min, dist$size_max)
    ) %>%

  # Compute sales from size and share
  mutate(sales = (share / 100) * size)
```

We then merge the development sample and the market sample into a single Sertkaya sample:

```{r, join-sertkaya-dev-market}
sertkaya2014 <-
  rbind(sertkaya2014_dev, select(sertkaya2014_market, -c(share, size))) %>%
  mutate(phase = factor(phase, levels=PHASES, ordered=TRUE)) %>%
  arrange(subject, src, phase)
```

and then merge the sampled additional data (supply chain activities, etc) into the full Sertkaya sample.
The additional costs in this additional sample is then added onto the appropriate phase costs already present in the Sertkaya sample,
and the additional cost column is removed.
From this point forwards it is therefore impossible to distinguish between base phase costs and additional costs added to that phase.

```{r, join-sertkaya-dev-additional}
sertkaya2014 <-

  # Merge dev samples with additional supply chain costs samples (by left join)
  merge(sertkaya2014, sertkaya2014_additional,
             by=c('subject', 'phase'), all.x = TRUE) %>%

  # Add supply chain activities cost to phase cost
  # Checks for NAs since the left join spawns NAs in the add_cost column
  mutate(cost = cost + ifelse(is.na(add_cost), 0, add_cost)) %>%

  # Remove supply chain costs column
  select(-add_cost)
```

Since the Sertkaya data was expressed in millions of USD, percentages, and months we here normalize the sample into USD, fractions, and years respectively.

```{r, normalize-sertkaya}
sertkaya2014 <- sertkaya2014 %>%
  mutate(time = time / 12,     # Convert months to years
         cost = cost * 10^6,   # Convert from million usd to usd
         sales = sales * 10^6, # Convert fom million usd to usd
         prob = prob / 100)    # Convert from percentage to fraction
```

Finally we sample developer discount rates and add it to our Sertkaya sample.

```{r, sertkaya-add-discount-rate}
sertkaya2014_agents <-
  data.frame(subject = sertkaya2014_subjects,
             discount_rate_priv =
               rtriangle2(length(sertkaya2014_subjects),
                          sertkaya2014_discount_rate_dist$min,
                          sertkaya2014_discount_rate_dist$max,
                          sertkaya2014_discount_rate_dist$mid))

# Left join
sertkaya2014 <- merge(sertkaya2014, sertkaya2014_agents, by='subject', all.x=TRUE)
```

<!--
The table below is an excerpt of the sampled data ordered by subject and then phase.

```{r, sertkaya-sample-excerpt, echo=FALSE}
sertkaya2014 %>%
  arrange(subject, phase) %>%
  head(n=25) %>%
  kable
```
-->

## DRIVE-AB distribution
The following is an approximation of the data used in DRIVE-AB final report (2018).
Some deviations (reported below) have been made as some of the DRIVE-AB assumptions are not compatible with our assumptions.

```{r, driveab-dist, echo=FALSE}
prob <- data.frame(phase = DEVELOPMENT_PHASES,
                   min = c(17.5, 25, 34, 31.4, 83),
                   mid = c(35.2, 33, 50, 67, 85),
                   max = c(69, 83.7, 74, 78.6, 99))

time <- data.frame(phase = DEVELOPMENT_PHASES,
                   min = c(52, 9, 9, 10, 6),
                   mid = c(66, 10.5, 13.33, 21.8, 9),
                   max = c(72, 21.6, 30, 47, 12.5))

# TODO: Cost of P2 is incorrectly reported in DRIVE-AB Final Report!
# We're using the numbers from Okhravi et al. (2018)
cost <- data.frame(phase = DEVELOPMENT_PHASES,
                   min = c(14.25, 13.1,  12.95,  27.99, 55.5),
                   mid = c(21.1,  24,    24.55,  62.6,  88.35),
                   max = c(29,    37.96, 46.36,  168.4, 127.91))

params <- data.frame(tot_sales_min = 0,
                     tot_sales_mid = 2559.5,
                     tot_sales_max = 4336,
                     market_years = 10)
```

```{r, print-driveab-dev-dist, echo=FALSE}
kable(prob, caption = 'Probability of success (%)')
kable(time, caption = 'Time (months)')
kable(cost, caption = 'Cost (million USD)')
```

In line with the assumptions of DRIVE-AB (2018) we assume that sales revenue linearly increase over a period of 10 years.
Patent expiry is assumed to occur at this point and we assume that all revenues drop to 0 beyond this point.
Specifically, we assume that the revenues of year 0 is 0 and then linearly increase until the area under the curve is equal to the total global net sales.
The first year will thus be non-zero if the market revenues of the project is non-zero.

```{r, print-driveab-market-dist, echo=FALSE}
kable(params, caption = 'Additional parameters')
```


## DRIVE-AB sample

We first sample development data from the DRIVE-AB distribution.

```{r, sample-driveab-dev}
# Subjects must not overlap across datasets
last_sertkaya_subject <- max(sertkaya2014_subjects)
first_subject <- last_sertkaya_subject + 1
last_subject <- last_sertkaya_subject + N

driveab2018_dev <- data.frame(
  subject = rep(first_subject:last_subject, each = num_phases),
  phase = DEVELOPMENT_PHASES,
  time = rtriangle2(N * num_phases, time$min, time$max, time$mid),
  cost = rtriangle2(N * num_phases, cost$min, cost$max, cost$mid),
  prob = rtriangle2(N * num_phases, prob$min, prob$max, prob$mid),
  sales = 0
  )
```

We then sample market data from the DRIVE-AB distribution.

```{r, sample-driveab-market}
# TODO: Should be from additional parameters table.
num_market_years <- length(MARKET_PHASES)

# Use same subjects as in development sample
driveab2018_subjects <- unique(driveab2018_dev$subject)

# Build data frame
driveab2018_sales <- data.frame(
  subject = rep(driveab2018_subjects, each = num_market_years),
  phase = MARKET_PHASES,
  time = 12,  # months
  cost = 0,   # million usd
  prob = 100, # percentage
  tot_sales = rep(rtriangle(N,
                 params$tot_sales_min,
                 params$tot_sales_max,
                 params$tot_sales_mid),
           each = num_market_years)
  ) %>%

  # Interpolate yearly sales
  mutate(slope = (tot_sales * 2 / (num_market_years + 1)) / num_market_years,
        sales = 1:num_market_years * slope) %>%

  # Remove temp columns
  select(-tot_sales, -slope)
```

We then merge the development sample and the market sample into a single DRIVE-AB sample.
We also normalize time, costs, revenues, and probabilities.

```{r, merge-driveab-sample}
driveab2018 <-

  # Join development and market data
  rbind(driveab2018_dev, driveab2018_sales) %>%

  # Add data source names and factorize phases
  mutate(src = 'DRIVE-AB (2018)',
         phase = factor(phase, levels=PHASES, ordered=TRUE)) %>%

  # Sort
  arrange(subject, src, phase) %>%

  # Normalize sampled values
  mutate(time = time / 12,     # Convert months to years
         cost = cost * 10^6,   # Convert from million usd to usd
         sales = sales * 10^6, # Convert from million usd to usd
         prob = prob / 100)    # Convert from percentage to fraction
```

Finally we sample developer discount rates and add it to our DRIVE-AB sample.

```{r, sample-driveab-discountrates}
driveab2018_agents <-
  data.frame(subject = driveab2018_subjects,
             discount_rate_priv = runif(length(driveab2018_subjects), 0.05, 0.3))

# Left join
driveab2018 <- merge(driveab2018, driveab2018_agents, by='subject', all.x=TRUE)
```



## Additional parameters
Before proceeding, we'll combine all datasets (sources) into a single dataset containing all sources.

```{r, combine}
phases <- rbind(sertkaya2014, driveab2018) %>%
          arrange(subject, src, phase)
```

```{r, precompute, include=FALSE, dependson=-1}
# To avoid recomputing all the time we'll also store the names of the different sources:
sources <- unique(phases$src)
# To avoid misspellings of factors, let's use levels:
metrics <- c('cashflow', 'ev', 'pv', 'epv')
cum_metrics <- c('cum', 'env', 'npv', 'enpv')
```

Later we will apply interventions to this dataset and thereby create multiple permutations/versions of every observation.
This means that we must keep track of which intervention we're currently looking at, and as such we'll add that column immediately, and declare all the current data as suffering from "no intervention".
In terms of a randomized controlled trial, this is the "control group".
When we apply different interventions to the control group we will thus create different "treatment groups".
As the interventions are applied to the control group rather than to completely new samples, we are able to perform "within subject analysis" rather than having to resort to "across subject analysis".

```{r, add-placeholders, dependson=-1}
phases$prizes <- 0
phases$intervention <- 'NONE'
```

Let us add a "public" or "social" discount rate.
Meaning the cost of capital for the benefactor, i.e. for the body that pays the intervention with no expectation of monetary return.
This parameter is used in the analysis, where its raison d'etre is also further explained.

We assume that the benefactor is the public sector and use a uniformly distributed discount rate.
Public discount rate varies across subjects but not within.

In the analysis we will also explore the effect of various levels of public sector inefficiency.
The assumptions are explained in further detail in the analysis section.
In most of the calculations, the inefficiency parameter is ignored, and when used we will control for it.
As such, we can explore a wide range of inefficiencies.

```{r, sample-discount-rates-and-inefficiency, dependson=-1}
public_discount_rate_min = 0.035
public_discount_rate_max = 0.045

public_inefficiency_min <- 0
public_inefficiency_max <- 3

subjects <- unique(phases$subject)
agents <- data.frame(
  subject = subjects,
  inefficiency = runif(length(subjects), public_inefficiency_min, public_inefficiency_max),
  discount_rate_publ = runif(length(subjects), public_discount_rate_min, public_discount_rate_max))

phases <- merge(phases, agents, by='subject', all.x=TRUE)
```


## Summary statistics
We now present some summary statistics to sanity check that our samples seem to be properly drawn from their respective distributions.
We first plot development data.

```{r, summary-violins, echo=FALSE, warning=FALSE, message=FALSE}
phases %>%
  filter(phase %in% DEVELOPMENT_PHASES) %>%
  ggplot(aes(phase, cost/10^6, color=src, fill=src)) +
  geom_violin() +
  facet_wrap(. ~ phase, scale='free') +
  theme(legend.position='top',
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  ylab('Cost (million USD)')
phases %>%
  filter(phase %in% DEVELOPMENT_PHASES) %>%
  ggplot(aes(phase, time, color=src, fill=src)) +
  geom_violin() +
  facet_wrap(. ~ phase, scale='free') +
  theme(legend.position='top',
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  ylab('Time (months)')
phases %>%
  filter(phase %in% DEVELOPMENT_PHASES) %>%
  ggplot(aes(phase, prob*100, color=src, fill=src)) +
  geom_violin() +
  facet_wrap(. ~ phase, scale='free') +
  theme(legend.position='top',
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  ylab('Probability of success (%)')
```

Below we plot the sampled sales data.

```{r, summary-sales, echo=FALSE}
phases %>%
  filter(phase %in% MARKET_PHASES) %>%
  ggplot(aes(phase, sales/10^6, color=src, fill=src)) +
  geom_violin() +
  facet_wrap(. ~ phase, scale='free') +
  theme(legend.position='top',
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  ylab('Sales (million USD)')

phases %>%
  filter(phase %in% MARKET_PHASES) %>%
  ggplot(aes(phase, sales/10^6, color=src, fill=src)) +
  geom_violin() +
  theme(legend.position='top',
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  ylab('Sales (million USD)')

phases %>%
  group_by(src, subject) %>%
  summarize(tot_sales = sum(sales)) %>%
  ggplot(aes(src, tot_sales/10^6, fill=src)) +
  geom_violin() +
  theme(legend.position='top',
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.major.x=element_blank()) +
  ylab('Total sales (million USD)')
```

Finally, we plot the discount rate data.

```{r, summary-discount-rates, echo=FALSE}
phases %>%
  filter(phase %in% DEVELOPMENT_PHASES) %>%
  ggplot(aes(phase, discount_rate_priv*100, color=src, fill=src)) +
  geom_violin() +
  ylab('Discount rate (%)') +
  xlab('Phase') +
  theme(legend.position = 'top')
```

Interestingly, some parameters are quite dispersly distributed between phases.
Below, we plot the mean percentage of a given property occuring in a given phase for all phases.

```{r, summary-phase-distribution-means, echo=FALSE, warning=FALSE, message=FALSE}
# Transform: phase properties to long from wide
phase_props <- phases %>%
  filter(phase %in% DEVELOPMENT_PHASES) %>%
  select(src, subject, phase, cost, time, prob) %>%
  gather(key='prop', value='value', -src, -subject, -phase) %>%
  group_by(src, subject, prop) %>%
  mutate(total = sum(value),
         ratio = value / total) # NOTE: will cause NaN if 0/0

phase_props %>%
  group_by(src, phase, prop) %>%
  summarise(ratio = mean(ratio)) %>%
  filter(is.finite(ratio)) %>%
  ggplot(aes(src, ratio * 100)) +
  geom_bar(stat='identity', aes(fill=phase), position='stack') +
  labs(fill='') +
  facet_wrap(. ~ prop) +
  theme(axis.text.x = element_text(angle=90, hjust=1))

phase_props %>%
  group_by(src, phase, prop) %>%
  summarise(ratio = mean(ratio)) %>%
  filter(is.finite(ratio)) %>%
  ggplot(aes(phase, ratio * 100)) +
  geom_bar(stat='identity', aes(fill=src), position='dodge') +
  labs(fill='') +
  facet_wrap(. ~ prop) +
  theme(axis.text.x = element_text(angle=90, hjust=1),
        legend.position = 'top')
```


# Valuation metrics
We employ the following financial metrics for cashflows:

- Non-capitalized value / Out-of-pocket value
- Risk-adjusted value (rV) / Expected value (EV)
- Capitalized value / Present value (PV)
- Risk-adjusted present value (rPV) / Expected present value (EPV)

Symmetrically, when cumulating cashflows, the above financial metrics are known as:

- Cumulative non-capitalized value / Cumulative out-of-pocket value
- Cumulative risk-adjusted value (Cumulative rV) / Cumulative expected value (Cumulative EV)
- Net present value (NPV)
- Risk-adjusted net present value (rNPV) / Expected net present value (ENPV)

We compute **Expected Value (EV)** as:

$$
EV_t = (R_t - C_t) * P_t
$$

where $R_t$ and $C_t$ are the revenues and costs (respectively) at time $t$, and $P_t$ the probability of reaching the cashflow from the point of evaluation.
The probability of reaching a given timestep $t_n$ from a point of evaluation $t_0$ is simply computed as: $P_t = \prod_{t_0}^{t^n}$.
Next, we compute **Present Value (PV)** as:

$$
\mathit{PV}_t = \frac{R_t - C_t}{(1 + i)^t}
$$

where $i$ is the discount rate of the evaluator, and $t$ is the time to the phase from the point of evaluation.
We compute **Expected Present Value (EPV)** as:

$$
\mathit{EPV}_t = \frac{R_t - C_t}{(1 + i)^t} * P_t
$$

Moving on to the cumulative valuations, we compute **Net Expected Value (ENV)**, **Net Present Value (NPV)**, and **Expected Net Present Value (ENPV)** as:
$\sum_{t\in T} \mathit{EV}_t$

$$
\mathit{ENV_T} = \sum_{t\in T} EV_t\\
$$

$$
\mathit{NPV_T} = \sum_{t\in T} \mathit{PV}_t\\
$$

$$
\mathit{ENPV_T} = \sum_{t\in T} \mathit{EPV}_t\\
$$

respectively, where $t$ is the time to the phase, and $T$ is the times to all timesteps of all phases for the project in evaluation.

<div class="alert alert-danger">
TODO: Verify that the probability portion of ENPV is actually computed accordingly!
</div>


# Valuation methods
As phase durations are long, the time value of money not only greatly reduces the attractiveness of revenues, but also dampen the pain of costs.
To take the time value of money into account we must make an assumption about how a real world evaluation of a project periodizes future costs, revenues and probabilities.
In other words, how a hypothetical evaluator chooses to transform a sequence of discrete phases into a sequence of discrete and uncertain cashflows.
We make the assumption that the evaluator converts every phase into a series of years in order to properly discount the cashflow of the given phase.
This method yields slightly different results when compared to simply applying financial valuation metrics to the sequence of phases under the assumption that all cashflows for a given phase occur immediately upon entering that phase.
To elucidate the consequence of these differences we will first apply financial metrics directly to the phase-based data, then transform the original data to a year-based form and apply the same metrics, and then finally compare the two.

## Phase-based method
We begin by assuming that all cashflows related to a phase occur immediately upon phase entry and compute Expected Value (EV), Present Value (PV), and Expected Present Value (EPV) of all phases from the perspective of all phases.
We then cumulate these metrics in order to, respectively, compute cumulative EV, Net Present Value (NPV), and Expected Net Present Value (ENPV) from any phase to any phase.

```{r, phase-based-valuation}
# TODO: Use the same function for all valuations.
# Should not matter whether it's phasely or yearly.
phase_based_valuation <- function(phs) {
  result <- tibble()
  for (frm in PHASES) {
    rows <- phs %>%
      filter(phase >= frm) %>%
      group_by(src, intervention, subject) %>%
      arrange(phase) %>%
      mutate(from = factor(frm, levels=PHASES, ordered=TRUE),
             time_to = cumsum(time) - time,
             cum_prob = cumprod(prob),
             prob_to = cum_prob / prob,
             # cashflows
             cashflow = sales + prizes - cost,
             ev = cashflow * prob_to,
             pv = cashflow / ((1 + discount_rate_priv) ^ time_to),
             epv = pv * prob_to,
             # cumulatives
             cum = cumsum(cashflow),
             env = cumsum(ev),
             npv = cumsum(pv),
             enpv = cumsum(epv),
      )
      result <- bind_rows(result, rows)
  }
  result
}

phasely_valuation <- phase_based_valuation(phases)
```

Before plotting we begin with some data wrangling.

```{r, phase-based-wrangling}
# Long
phasely_valuation_long <- phasely_valuation %>%
  select(src, intervention, subject, from, phase,
         cashflow, ev, pv, epv,
         cum, env, npv, enpv) %>%
  gather('metric', 'value', -src, -intervention, -subject, -from, -phase) %>%
  transform(metric = factor(metric, levels = c(metrics, cum_metrics)))

# Final valuations
phasely_final_valuation <- phasely_valuation %>%
  group_by(src, subject, from) %>%
  arrange(phase) %>%
  summarize(cum = tail(cum, n=1),
            epv = tail(epv, n=1),
            npv = tail(npv, n=1),
            enpv = tail(enpv, n=1))

# Final long
phasely_final_valuation_long <- phasely_valuation_long %>%
  filter(metric %in% cum_metrics) %>%
  group_by(src, subject, from, metric) %>%
  arrange(phase) %>%
  summarize(value = tail(value, n=1))
```

Let us then plot the value of taking the project from beginning (i.e. pre-clinical) to end (i.e. the final market year), using our cumulative valuation metrics.
Note the usage of different scales across the different metrics due the vastly different values.


```{r, phase-based-summary, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
phasely_final_valuation_long %>%
  filter(from == 'PC' & metric %in% cum_metrics) %>%
  ggplot(aes(metric, value / 10^6, fill=src)) +
  geom_boxplot() +
  ylab('USD (millions)') +
  xlab(element_blank()) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +
  facet_wrap(. ~ metric, scale='free', nrow=1) +
  theme(legend.position = 'top')
```

Another way to look at the data is to consider how starting at different phases alter the value of the project.
Below we combine all datasets and plot the mean value (across all datasets) of bringing the project to completion from various starting phases, using the four cumulative metrics.
The vertical lines delimit +/- 1 standard deviation from the sample mean (i.e. ~68% of the data).
The second plot depicts the mean valuations within each dataset.

```{r, phase-based-summary2-tempppp, echo=FALSE}
pos <- position_dodge(0.4)
phasely_final_valuation_long %>%
  group_by(from, metric) %>%
  summarize(mu = mean(value),
            std = sd(value)) %>%
  ggplot(aes(from, mu, color=metric, group=metric)) +
  geom_linerange(aes(ymin=mu-std, ymax=mu+std), position=pos, size=1) +
  geom_line(position=pos, size=1, linetype='dotted') +
  geom_point(position=pos, size=2) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 5),
                     label = unit_format(unit = '', scale = 1e-9)
                     ) +
  xlab(element_blank()) + ylab('USD (billions)') +
  theme(legend.position = 'top')

# TODO: Add linerange like in the plot above?
phasely_final_valuation_long %>%
  ggplot(aes(from, value, color=src, group=interaction(src, metric))) +
  stat_summary(fun.y=mean, geom='line') +
  stat_summary(fun.y=mean, geom='point') +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 5),
                     label = unit_format(unit = '', scale = 1e-9)
                     ) +
  xlab(element_blank()) + ylab('USD (billions)') +
  facet_wrap(. ~ metric) +
  theme(legend.position = 'top',
        axis.text.x = element_text(angle=90, hjust=1))
```


## Year-based method
To consider the fact that all cashflows of a phase do not occur immediately upon phase-entry we convert our phase-based data to year-based data and make assumptions as to how the values are interpolated over the years of a phase.
We use the function below to convert from phase-form to year-form.
We use the same function to convert to year based data again after having introduced prizes.
Note however that we do not interpolate prizes but rather assume that they are introduced as lump sums.

```{r, year-based-conversion}
#' Converts a data set in phase-form to year-form.
#'
#' @param phases Dataframe in phase-form.
#' @return Dataframe in year-form
to_years <- function (phases) {

  # Add timestamps to every observation
  phases <- phases %>%
    group_by(src, intervention, subject) %>%
    arrange(phase) %>%
    mutate(time_to = cumsum(time) - time)

  # Compute cost steps
  cost_step <- (phases$cost / phases$time)
  cost_remainder <- phases$cost - cost_step * floor(phases$time)

  # Compute sales steps
  sales_step <- (phases$sales / phases$time)
  sales_remainder <- phases$sales - sales_step * floor(phases$time)

  # Compute prob steps
  prob_step <- phases$prob ^ (1 / phases$time)
  prob_remainder <- phases$prob / (prob_step ^ floor(phases$time))

  # Compute time steps
  time_step <- 1
  time_remainder <- phases$time - floor(phases$time)

  # Transform: to phase-local years
  phase_years <- tibble()
  for (x in 1:ceiling(max(phases$time) + 1)) {

    # Compute step-based properties
    has_decimals <- phases$time - floor(phases$time) != 0
    whole_step   <- x <= phases$time
    partial_step <- x <= phases$time + 1 & has_decimals

    cost   <- ifelse(whole_step, cost_step, cost_remainder)
    sales  <- ifelse(whole_step, sales_step, sales_remainder)
    prob   <- ifelse(whole_step, prob_step, prob_remainder)
    time   <- ifelse(whole_step, time_step, time_remainder)
    prizes <- if (x == 1) phases$prizes else 0 # Immediate lump-sum

    # Make tibble
    year <-
      tibble(src                = phases$src,
             intervention       = phases$intervention,
             subject            = phases$subject,
             phase_year         = x,
             phase              = phases$phase,
             inefficiency       = phases$inefficiency,
             time,
             cost,
             sales,
             prizes,
             prob,
             discount_rate_publ = phases$discount_rate_publ,
             discount_rate_priv = phases$discount_rate_priv
             ) %>% filter(whole_step | partial_step) # Only keep relevant data

    # Append
    phase_years <- bind_rows(phase_years, year)
  }
  phase_years
}

# And then we convert
years <- to_years(phases)
```

We have now converted our phase-based data to year-based data.
It should be noted that the function does not distribute the phase-based data over a series of equidistant years.
Data points are only equidistant within a phase, but not necessarily across.
In other words, if P1 entry would occur after 5.3 years then we will distribute PC properties over the 6 first years.
If the duration of P1 is 2.5 years then P2 would start at year 5.3 and end at year 7.8.
While we would divide P1 into three equidistant (years) points (years), that start from year 5.3, 6.3, and 7.3 (respectively) they are not equidistant from the PC steps.

We can now compute the same valuation metrics we computed for the phase-based method but this time for the year-based method:

```{r, year-based-valuation}
yearly_valuation <- tibble()
for (from in PHASES) {
  pyfp <- years %>%
    filter(phase >= from) %>%
    group_by(src, subject, intervention) %>%
    arrange(phase, phase_year) %>%
    mutate(from     = factor(from, levels=PHASES, ordered=TRUE),
           time_to  = cumsum(time) - time,
           year     = round(time_to), # TODO: Should perhaps just be round?
           cum_prob = cumprod(prob),
           prob_to  = cum_prob / prob,
           # cashflows
           cashflow = sales + prizes - cost,
           ev       = cashflow * prob_to,
           pv       = cashflow / ((1 + discount_rate_priv) ^ time_to),
           epv      = pv * prob_to,
           # cumulatives
           cum      = cumsum(cashflow),
           env      = cumsum(ev),
           npv      = cumsum(pv),
           enpv     = cumsum(epv))
    yearly_valuation <- bind_rows(yearly_valuation, pyfp)
}
```

Again, we must follow this up with some data wrangling to prepare for analysis.

```{r, year-based-wrangling}
# Long
yearly_valuation_long <- yearly_valuation %>%
  select(src, intervention, subject, from, year,
         cashflow, ev, pv, epv,
         cum, env, npv, enpv) %>%
  gather('metric', 'value', -src, -intervention, -subject, -from, -year) %>%
  transform(metric = factor(metric, levels = c(metrics, cum_metrics)))

# Final valuations
yearly_final_valuation <- yearly_valuation %>%
  group_by(src, subject, from) %>%
  arrange(year) %>%
  summarize(cum = tail(cum, n=1),
            epv = tail(epv, n=1),
            npv = tail(npv, n=1),
            enpv = tail(enpv, n=1))

# Final long
yearly_final_valuation_long <- yearly_valuation_long %>%
  filter(metric %in% cum_metrics) %>%
  group_by(src, subject, from, metric) %>%
  arrange(year) %>%
  summarize(value = tail(value, n=1))
```


As with the phase-based method, let us also do some descriptive statistics.
We begin with the value of taking the project from beginning (i.e. pre-clinical) to end (i.e. the final market year), using our cumulative valuation metrics.
Again, note the usage of different scales across the different metrics due the vastly different values.

```{r, year-based-summary, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
# TODO: Remove x-tick label
yearly_final_valuation_long %>%
  filter(from == 'PC' & metric %in% cum_metrics) %>%
  ggplot(aes(metric, value/10^6, fill=src)) +
  geom_boxplot() +
  xlab(element_blank()) +
  ylab('USD (millions)') +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +
  facet_wrap(. ~ metric, scale='free', nrow=1) +
  theme(legend.position = 'top')
```

When we've transformed the data to year-based we've moved from an ordinal to a ratio scale.
As such it makes sense to explore how these valuations emerge as a consequence of the yearly cashflows of a project.
From top-left to bottom-right: out-of-pocket cashflows, risk-adjusted/expected value (EV), capitalized/present value (PV), risk-adjusted/expected capitalized/present value (EPV).
The middle line in each ribbon tracks the mean value, while the edges capture all values within 2 standard deviations of the mean (meaning 95% of the data).

```{r, year-based-summary2, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
yearly_valuation_long %>%
  filter(from == 'PC' & metric %in% metrics) %>%
  group_by(src, metric, year) %>%
  summarize(mu = mean(value),
            std = sd(value)) %>%
  ggplot(aes(year, mu)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 8),
                     label = unit_format(unit='', scale = 1e-6)) +
  xlab(element_blank()) +
  ylab('USD (millions)') +
  geom_ribbon(aes(x=year, ymin=(mu-std*2), ymax=(mu+std*2), fill=src), alpha=.4) +
  geom_line(aes(color=src)) +
  facet_wrap(. ~ metric, scale='free_y', ncol=2)
```

If we cumulate these values over time, we get the cumulative versions of these metrics.
These can be thought of as the value of planning to run the project for x years, from the start.
The x-axis consequently describes the planned "point of exit".
From top-left to bottom right: cumulative out-of-pocket cashflows, cumulative risk-adjusted/expected value (EV), capitalized/net present value (NPV), and risk-adjusted/expected capitalized/net present value (ENPV).

```{r, year-based-summary3, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
yearly_valuation_long %>%
  filter(from == 'PC' & metric %in% cum_metrics) %>%
  group_by(src, metric, year) %>%
  summarize(mu = mean(value),
            std = sd(value)) %>%
  ggplot(aes(year, mu)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 8),
                     label = unit_format(unit='', scale = 1e-6)) +
  xlab(element_blank()) +
  ylab('USD (millions)') +
  geom_ribbon(aes(x=year, ymin=(mu-std*2), ymax=(mu+std*2), fill=src), alpha=.4) +
  geom_line(aes(color=src)) +
  facet_wrap(. ~ metric, scale='free_y', ncol=2)
```

Again, we can look at how different starting phases alter the value of a project.
The first plot depicts the mean value (across datasets) of bringing the project to completion from whatever starting phase we're currently considering.
The vertical lines delimit +/- 1 standard deviations from the sample mean (i.e. ~68% of the data).
The second plot depicts the mean of the same valuations but for each individual dataset.

```{r, year-based-summary4, echo=FALSE}
pos <- position_dodge(0.4)
yearly_final_valuation_long %>%
  group_by(from, metric) %>%
  summarize(mu = mean(value),
            std = sd(value)) %>%
  ggplot(aes(from, mu, color=metric, group=metric)) +
  geom_linerange(aes(ymin=mu-std, ymax=mu+std), position=pos, size=1) +
  geom_line(position=pos, size=1, linetype='dotted') +
  geom_point(position=pos, size=2) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 5),
                     label = unit_format(unit = '', scale = 1e-9)
                     ) +
  xlab(element_blank()) + ylab('USD (billions)') +
  theme(legend.position = 'top')

yearly_final_valuation_long %>%
  ggplot(aes(from, value, color=src, group=interaction(src, metric))) +
  stat_summary(fun.y=mean, geom='line') +
  stat_summary(fun.y=mean, geom='point') +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 5),
                     label = unit_format(unit = '', scale = 1e-9)
                     ) +
  xlab(element_blank()) + ylab('USD (billions)') +
  facet_wrap(. ~ metric) +
  theme(legend.position = 'top',
        axis.text.x = element_text(angle=90, hjust=1))
```

The table below summarizes the valuation metrics from the start of pre-clinical, in millions.

```{r, year-based-table, echo=FALSE}
sub <- yearly_final_valuation_long %>%
  filter(from=='PC' & metric %in% cum_metrics) %>%
  group_by(src, metric) %>%
  summarize(mean  = mean(value) / 10^6,
            median = median(value) / 10^6,
            std = sd(value) / 10^6) %>%
  arrange(metric)
kable(sub)
```


## Comparing methods
Let us compare the two methods by looking at the cumulative valuations from different starting points.
In the first two plots we observe that the simple valuation metrics cumulative cashflows and ENV, does not significantly differ between the two methods in any of the datasets.
In fact, the cumulative metric should yield exactly the same results in both methods as neither discounting nor probability is taken into consideration.
When computing ENV however, we take probability into account, and as a consequence, the outcome could in theory be different, but in practice, i.e. in the plot below, we observe that the difference is insignificant.

```{r, combine-methods, echo=FALSE}
pwise <- phasely_final_valuation_long
ywise <- yearly_final_valuation_long
pwise$method <- factor('phase', levels=c('phase', 'year'))
ywise$method <- factor('year', levels=c('phase', 'year'))
both <- bind_rows(pwise, ywise)
```

Taking discounting into consideration however, makes the two methods yield slightly different results.
The following two plots illustrate that difference for the metrics NPV and ENPV.
Again, in all datasets, from multiple starting phases.

```{r, methods-comparison, echo=FALSE}
for (curr in c('cum', 'env', 'npv', 'enpv')) {
  p <- both %>%
    filter(metric == curr & from %in% c(DEVELOPMENT_PHASES, 'M1')) %>%
    ungroup %>%
    ggplot(aes(src, value / 10^6, color=method, fill=method)) +
    geom_boxplot(alpha=0.3) +
    facet_wrap(. ~ from, scales='free', ncol=6) +
    ylab('USD (millions)') +
    xlab(element_blank()) +
    theme(axis.text.x = element_text(angle=90, hjust=1),
          axis.text.y = element_text(angle=90),
          legend.position = 'top') +
    ggtitle(curr)
  print(p)
}
```

Evidently, there are no differences between the methods in the non-discounted valuation metrics.
Interestingly however, the difference also seems comparatively small in the discounted metrics, but the yearly method does indeed yield slightly higher values.
The difference between the two methods is more pronounced the earlier your venture point of valuation since the effect of discounting has more time to accumulate.

Finally, let us compare the mean ENPV (starting from pre-clinical) of the Sertkaya data using both methods to the mean ENPV reported for the same indications in Table 13 of Sertkaya et. al (2014).
Seeing that we've attempted to reflect their assumptions as closely as possible, the resulting ENPV should not be too far apart.

```{r, sertkaya-enpv-paper-comparison, echo=FALSE}
expected <-
  data.frame(src = INDICATIONS,
             original = c(-2.7 * 10^6,
                          27.1 * 10^6,
                          37.4 * 10^6,
                          8.9  * 10^6,
                          21.9 * 10^6,
                          -4.5 * 10^6))

actual_phasely <- phasely_final_valuation %>%
  filter(from == 'PC') %>%
  group_by(src) %>%
  summarize(phasely = mean(enpv))

actual_yearly <- yearly_final_valuation %>%
  filter(from == 'PC') %>%
  group_by(src) %>%
  summarize(yearly = mean(enpv))

actual <- merge(actual_yearly, actual_phasely, by='src')
comparison <- merge(expected, actual, by='src', all.x=TRUE) %>%
  # Convert to millions
  mutate(original = original / 10^6,
         phasely  = phasely / 10^6,
         yearly   = yearly / 10^6) %>%
  # Prettier names
  rename('Sertkaya et. al (2014)' = original)

# Print table in millions
comparison %>%
  mutate(yearly = round(yearly, 1),
         phasely = round(phasely, 1)) %>%
  kable(caption = 'Mean ENPV comparison (million USD, rounded)')

# Plot comparison
comparison %>%
  gather(method, value, -src) %>%
  # Control printing order
  ggplot(aes(src, value, fill=method)) +
  geom_bar(stat='identity', position=position_dodge()) +
  facet_wrap(. ~ src, scale='free_x', nrow=1) +
  ylab('Mean ENPV (million usd)') +
  xlab(element_blank()) +
  theme(legend.position = 'top',
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
```



# Interventions
We now introduce five interventions (treatments) to our base data sets and later analyze their effects on the valuation metrics.
To "err on the rigth side", we choose to use the yearly rather than the phasely method since this yield higher values for NPV and ENPV.
We model these interventions as qualitatively (categorically) different, as they operate on different R&D phases, but theoretically they could be considered the same intervention that is quantitatively (numerically) different in terms of their actuation time.
The intervention can be described as a non-dilutive and unconditional prize.
This intervention can be considered a generalization of what is commonly referred to as either a market entry reward or a phase entry reward, where we've generalized the time of actuation.
Prize size is quantitatively varied stochastically.
We implement the intervention as a function `intervene` as follows:

```{r, function-intervene}
log10_sample <- function (n, min, max, magnitude_min, magnitude_max) {
  runif(n, min, max) * (10 ^ runif(n, magnitude_min, magnitude_max))
}

prize_samples <- log10_sample(N, 1, 19.999, -1, 3) * 10^6 # Reuse intervention samples across phases
intervene <- function (phases, target_phase, intervention_name) {
  data.frame(phases) %>%
    mutate(intervention = intervention_name,
           prizes = ifelse(phase == target_phase, prize_samples, 0))
}
```

We can then treat copies of the original phase-based data set and merge it into one larger data set, like this:

```{r, sample-prizes}
intervened <- rbind(phases,
  intervene(phases, 'P1', 'P1ER'),
  intervene(phases, 'P2', 'P2ER'),
  intervene(phases, 'P3', 'P3ER'),
  intervene(phases, 'P4', 'P4ER'),
  intervene(phases, 'M1', 'PDMER'))
```

Note that we are logarithmically sampling prize sizes.
This is because we assume that the absolute difference in effect will be much smaller when prize sizes are very small, as compared to when prize sizes are very large, and hence need more samples at the "bottom" to properly saturate the space.
In the analysis we at all times "control for" prizes which means that the chosen distribution does not affect any of the conclusions beyond sample saturation.
The sampled prizes are summarized in the histogram below.

```{r, prize-summary, echo=FALSE, message=FALSE}
print(intervened %>%
      filter(prizes > 0) %>%
      ggplot(aes(prizes, fill=phase)) +
      geom_histogram() +
      facet_wrap(interaction(intervention, phase)~., ncol=3) +
      scale_x_continuous(label = unit_format(unit='', scale=1e-9),
                         breaks = pretty_breaks(8)) +
      xlab('USD (billions)') +
      ylab(element_blank()) +
      theme(axis.ticks.y = element_blank(),
            axis.title.y = element_blank(),
            axis.text.y = element_blank()) +
      guides(fill = FALSE))
```

We then convert the data to yearly, and restructure it so that every row without an intervention is matched with the corresponding row with an intervention for every qualitatively different intervention.
Meaning that we duplicate ever original sample once for every phase of intervention.
Consequently, we can no longer plot the full data set without controlling for intervention.

```{r, add-prizes}
intervened_years <- to_years(intervened)

control <- filter(intervened_years, intervention == 'NONE')
treated <- filter(intervened_years, intervention != 'NONE')

comparable_years <-
  semi_join(treated, control, by=c('src', 'subject', 'phase', 'phase_year')) %>%
  group_by(src, subject) %>%
  arrange(phase, phase_year) %>%
  mutate(time_to = cumsum(time) - time)
```

# Analysis
The question we want to explore is whether it is cheaper for the benefactor to directly or indirectly fund antibiotics R&D.
Directly here refers to the idea of simply paying for development "at cost".
Indirectly refers to the idea of issuing prizes that encourage private developers to undertake a given activity with the hope of winning said prize.

We compare these two different approaches by comparing their expected costs when facing a hypothetical project entering pre-clinical.
We assume that the valuation metric that private actors employ is ENPV and that the valuation method is yearly.
We refer to this value as *private ENPV.*
As previously described, ENPV takes both the opportunity cost of capital and the risk of project failure into consideration.
In other words, ENPV computes the discounted expected value of (in this case) a series of investments with potential future return.

We assume that positive private ENPV in pre-clinical yields a go-decision while negative value yields a no-decision.
From a given sample we can then compute the ratio between the number of projects that face go-decision and the number that do not.
We refer to this as the go-rate.

While we now have a way of reasoning about the effectiveness of a given prize, we must combine that information with its cost in order to explore its efficiency.
In order to reason about the cost, for the benefactor of issuing a prize we compute the necessarily negative ENPV of issuing said prize.
This can be thought of as the expected, capitalized cost of issuing the intervention publicly and then paying for every successful candidate without receiving any financial return whatsoever.
The metric takes both the opportunity cost (cost of capital) and project risk of failure into consideration.
Taking opportunity cost into consideration is important as the benefactor looses the opportunity to activate their money elsewhere when making a payment to a beneficiary.
Taking risk into consideration is important as the benefactor will not necessarily pay the promised prize size, due to projects being highly risky.
The only cashflow considered in the ENPV calculation is the prize, but since we compute ENPV we take the fact that not all developers reach the point of the prize and that even if they do that time will be in the future.
We refer to the expected cost of a prize (i.e. indirect funding) as *indirect ENPV*.
As previously described, we assume that the benefactor is the public sector and employ a uniformly distributed discount rate between `r public_discount_rate_min * 100`% and `r public_discount_rate_max * 100`%.
Indirect ENPV can be thought of as the expected cost of issuing a prize (for the benefactor).

As we will compare the cost of issuing a prize (indirect funding) to that of directly paying for projects (direct funding) we must also have a way of estimating the cost of paying for projects at-cost.
We again take both the opportunity cost of capital and project risk of failure into consideration and therefore again employ ENPV.
We again disregard any project revenues, since we're again computing the cost of supporting the project as a benefactor
The cashflows used in the ENPV calculation are therefore all the costs.
We assume that the benefactor issuing the direct intervention is the same as the one issuing indirect interventions.
Hence, we use the same discount rate distribution in both cases
(`r public_discount_rate_min * 100`% - `r public_discount_rate_max * 100`%).
We refer to the expected cost of paying for the project at cost (i.e. direct funding) as *direct ENPV*.

| Valuation metric | Summary |
|-----|-----|
| Private ENPV  | The expected (private) value of a project.         |
| Indirect ENPV | The expected cost of issuing a prize.              |
| Direct ENPV   | The expected cost of paying for a project at-cost. |

We compute private, direct, and indirect ENPV like this:

```{r, compute-enpvs}
comparable_years <- comparable_years %>%
  arrange(time_to) %>%
  group_by(src, subject, intervention) %>%
  mutate(
         tot_prob = prod(prob),
         prob_to = cumprod(prob) / prob, # TODO: Is this correct?!?!
         cashflow_bef = sales - cost,
         cashflow_aft = sales - cost + prizes,
         enpv_prv_bef =
           cumsum((cashflow_bef / ((1 + discount_rate_priv) ^ time_to)) * prob_to),
         enpv_prv_aft =
           cumsum((cashflow_aft / ((1 + discount_rate_priv) ^ time_to)) * prob_to),
         enpv_ind =
           cumsum((-prizes / ((1 + discount_rate_publ) ^ time_to)) * prob_to),
         enpv_dir =
           cumsum((-cost / ((1 + discount_rate_publ) ^ time_to)) * prob_to)
         ) %>%
  select(-prob_to)
```

We extract the final ENPV values, i.e. the value of planning to run the project from pre-clinical to the end, like this:

```{r, compute-final-enpvs}
finals <- comparable_years %>%
  arrange(time_to) %>%
  group_by(src, subject, intervention, inefficiency) %>%
  # TODO: Previously I also grouped by tot_prob but this seems nonsensical.
  # Should I actually do that?
  mutate(prizes = sum(prizes)) %>%
  do(tail(., n = 1)) %>%
  select(prizes, enpv_prv_bef, enpv_prv_aft, enpv_ind, enpv_dir, tot_prob)
```

## Indirect: effectiveness
Determining the efficiency of an intervention means that we must take both its effectivess and its cost into consideration.
We will measure effectiveness as the likelihood that a given intervention turns a pre-clinical no-decision into a go-decision (on the basis of private ENPV), and we will measure cost as the previously computed indirect ENPV.

Before we proceed further however, let us first ensure that the issued prizes (i.e. the interventions) actually do have an effect on private ENPV.
As such there should be a correlation between prize size, regardless of intervention phase, and the improvement in private ENPV in all datasets.
By subtracting the private ENPV value before the application of the intervention from the private ENPV after the application of the intervention we get the improvement in private ENPV, i.e. the delta.
Since we're modeling non-dilutive prizes with no strings attached, the intervention will always improve private ENPV which means that the delta as a consequence always will be greater than zero.

```{r, prize-vs-private-enpv, echo=FALSE}
print(finals %>%
  ggplot(aes(prizes, enpv_prv_aft-enpv_prv_bef, col=intervention)) +
  geom_point(alpha=1, shape=1) +
  #geom_smooth(method='lm', se=FALSE, col='black') +
  facet_wrap(intervention ~ src, ncol=7, scale='free') +
  xlab('Prize') +
  ylab('Private ENPV') +
  #scale_x_continuous(label = unit_format(scale=1e-9, unit=''),
  #                   breaks = pretty_breaks(8)) +
  #scale_y_continuous(label = unit_format(scale=1e-6, unit='')) +
  theme(legend.position = 'top',
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        panel.spacing = unit(0, 'cm'),
        strip.text.x = element_text(margin = margin(0, 0, 0, 0, 'cm')),
        strip.text.y = element_text(margin = margin(0, 0, 0, 0, 'cm'))
  )
)
```

In the plots above, the data does not seem correlated.
If we however plot the same data on a log-log scale (see below) the correlation is evident.
As a side-note it is important to remember that the reason that there are very few samples at high x-values in the first set of plots is that we sampled intervention prize sizes logarithmically.
In the first set of plots the data *is* in fact correlated but the variance increases with x.

```{r, prize-vs-private-enpv-improvement, echo=FALSE}
print(finals %>%
  ggplot(aes(prizes, enpv_prv_aft-enpv_prv_bef, col=intervention)) +
  geom_point(alpha=1, shape=1) +
  #geom_smooth(method='lm', se=FALSE) +
  facet_wrap(intervention ~ src, ncol=7, scale='free') +
  xlab('Prize (log)') +
  ylab('Private ENPV (log)') +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = NULL,
                     labels = trans_format('log10', math_format(10^.x))) +
  scale_y_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = NULL,
                     labels = trans_format('log10', math_format(10^.x))) +
  theme(legend.position = 'top',
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        panel.spacing = unit(0, 'cm'),
        strip.text.x = element_text(margin = margin(0, 0, 0, 0, 'cm')),
        strip.text.y = element_text(margin = margin(0, 0, 0, 0, 'cm'))
  )
)
```

Other studies have shown, that the later a prize is awarded, the higher the size of the prize must be to achieve a comparative increase in ENPV.
This phenomena is clearly visible in our model when plotting the correlation between prize size and private ENPV improvement for all interventions on the same scale.
The data organizes itself into "layers", where for any given prize size, the resulting ENPV is higher for late stage interventions and lower for early stage interventions.

```{r, prize-vs-private-enpv-improvement2, echo=FALSE, warning=FALSE}
# TODO: This plot yields warnings!
print(finals %>%
  ggplot(aes(prizes, enpv_prv_aft - enpv_prv_bef, color=intervention)) +
  geom_smooth(method='lm', se=FALSE) +
  geom_point(shape=1) +
  xlab('Prize') +
  ylab('Private ENPV improvement') +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     labels = trans_format('log10', math_format(10^.x))) +
  scale_y_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     labels = trans_format('log10', math_format(10^.x))) +
  facet_wrap(. ~ src, ncol=4, 'free') +
  theme(legend.position = 'top')
)
```

Let us now move to estimating the interventions' improvement on pre-clinical go-decisions.
We assume that a pre-clinical go-decision will be reached if ENPV upon entering pre-clinical is at or above zero, and a no-decision reached if not.

```{r, precompute-go-decision}
finals$go <- factor(finals$enpv_prv_aft >= 0)
```

If we jitter plot prize size on the x-axis and the binary go-decision on the y-axis, we (expectedly) observe that as prizes increase, initial no-decisions are eventually turned into go-decisions.
If we look closely we even see that the range of prizes that turns no's into go's seems to be higher in later phases and lower in earlier.
This is of course also expected since we've already established that late-phase prizes must be higher to achieve an ENPV improvement comparable to early-phase prizes.

```{r, prize-vs-go-decision, echo=FALSE}
finals %>%
  ggplot(aes(prizes, go, color=intervention)) +
  geom_jitter(shape=1) +
  facet_grid(cols=vars(src), rows=vars(intervention)) +
  theme(legend.position = 'none') +
  ylab('Pre-clinical go-decision') +
  xlab('Prize') +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(seq(0,10,2))),
                     labels = trans_format('log10', math_format(10^.x)))
```

The analysis above is however also diffused by the fact that we are not differentiating between turning a no-decision into a go-decision and simply paying money to a project that already faced a go-decision.
Let us focus on projects that faced an initial no-decision.

```{r, filter-nos}
nos <- filter(finals, enpv_prv_bef < 0)
```

Running the same plot on the new subset we get a clearer picture of when no's actually are turned into go's.

```{r, prize-vs-go-decision-in-nos, echo=FALSE}
nos %>%
  ggplot(aes(prizes, go, color=intervention)) +
  geom_jitter(shape=1) +
  facet_grid(cols=vars(src), rows=vars(intervention)) +
  theme(legend.position = 'none') +
  ylab('Pre-clinical go-decision') +
  xlab('Prize') +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(seq(0,10,2))),
                     labels = trans_format('log10', math_format(10^.x)))
```

To more properly understand at what ranges the different interventions have their effects we can build a logistic regression model where prize size predicts no/go and then use that model to predict the probability of a particular prize yielding a go- as opposed to a no-decision.
We will refer to the predicted percentage of go-decisions under a given prize as the predicted go-rate of a prize or an intervention.

```{r, predict-go-in-nos}
go_model <- glm(
  go ~ prizes * interaction(src, intervention),
  data = nos,
  family = binomial(link='logit'))
nos$go_pred_prize <- predict(go_model, type='response')
```

With this we can reason about the average size at which a given intervention actually has an effect.
More precisely we can reason about the probability of a particular prize size turning a no-decision into a go-decision.
In the following plot we clearly see how late-phase prizes must be substantially higher to have the same probability of turning no-decisions into go-decisions as early-phase prizes.

```{r, prize-vs-predicted-go-in-nos, echo=FALSE}
nos %>%
  ggplot(aes(prizes, go_pred_prize*100, color=intervention)) +
  geom_line() +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     labels = trans_format('log10', math_format(10^.x))) +
  xlab('Prize') +
  ylab('Probability of no-to-go (%)') +
  facet_wrap(. ~ src)
```

When previously filtering out projects that already faced go-decisions we notice that a plethora of projects already faced go-decisions even without intervention.
Many (the author included) have suggested that prizes should be coupled with profitability analyses in order to avoid wasteful spending of public resources.
However, such a filtering process is likely to be prohibitively difficult in reality.
And even if conducted, the incentive for developers to "rig" the numbers and bend the truth is substantial.
Granting prizes to developers with projects that would have been pursued regardless of the existance of the prize is consequently assumed to be an unfortunate but possibly unavoidable reality.

Under this assumption we cannot employ the "cleaner" no-to-go model but must use all the data and use prize size to predict go-decisions in the existance of the noise caused by projects facing go-decisions irrespectively.
I.e. under the assumption that we cannot a priori distinguish between a sufficiently profitable project and one in need of an intervention we will assume that interventions are promised to all.

```{r, predict-go}
mod <- glm(
  go ~ prizes * interaction(src, intervention),
  data = finals,
  family = binomial(link='logit'))
finals$go_pred_prize <- predict(mod, type='response')
```

```{r, prize-vs-predicted-go, echo=FALSE}
finals %>%
  ggplot(aes(prizes, go_pred_prize*100, color=intervention)) +
  geom_line() +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     labels = trans_format('log10', math_format(10^.x))) +
  xlab('Prize') +
  ylab('Probability of pre-clinical go-decision (%)') +
  facet_wrap(. ~ src)
```


## Indirect: cost
We will now explore the correlation between prize size and indirect ENPV.
I.e. the correlation between the size of the prize in an indirect funding scheme and the cost of that scheme for the benefactor.
Note that indirect ENPV necessarily will be negative as the cost of paying the final prize is the only cashflow considered.
When plotting indirect ENPV however we present it as a positive number (i.e. as a cost) instead of a negative number (i.e. as a cashflow).

```{r, prize-vs-indirect-enpv-including-nos, echo=FALSE}
finals %>%
  #ggplot(aes(prizes / 10^6, -enpv_ind / 10^6, color=intervention)) +
  ggplot(aes(prizes, -enpv_ind, color=intervention)) +
  geom_point(shape=1) +
  geom_smooth(method='lm', se=FALSE) +
  facet_wrap(. ~ src, ncol=4) +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     #label = unit_format(unit = '')) +
                     labels = trans_format('log10', math_format(10^.x))) +
  scale_y_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     #label = unit_format(unit = '')) +
                     labels = trans_format('log10', math_format(10^.x))) +
  xlab('Prize') +
  ylab('Indirect ENPV (both go\'s and no\'s)') +
  theme(legend.position = 'top')
```

However, since not all projects will reach a go-decision, we cannot compute the total indirect cost as simply the expected cost of the intervention given the project's probabilities, but must instead compute the expected cost of the intervention given the project's probabilities and the owner's decision of whether to pursuit it or not.
In other words:

> An intervention will not have to fund projects ran by owners that (despite the existance of the intervention) choose to terminate their projects and consequently never reach the prize point.

In even other words, we assume that the final go-/no-decision of a project is based on whether private ENPV is zero or above.
When computing indirect ENPV however, we must only consider cashflows that private developers have *chosen* to undertake.
In other words, **indirect ENPV is *path dependent* on private ENPV**.
Importantly, private ENPV here refers to the valuation *after* the introduction of the intervention.
In summary, to compute the cost of indirect funding we must first determine which projects would reach go-decisions (and hence probabilitistically need to be funded) under said funding scheme (intervention).

Again, assuming that a pre-clinical go-decision is reached if ENPV after the introduction of the intervention is greater than or equal to 0, we can filter and keep only observations where we've reached a go-decision in pre-clinical and plot again.

Analyzing the new plot we realize that while paying for substantially fewer projects when issuing lower prizes, we still observe the same "stacking" of interventions as we did before removing non-go projects.

```{r, prize-vs-indirect-enpv, echo=FALSE}
finals %>%
  filter(go == TRUE) %>%
  ggplot(aes(prizes, -enpv_ind, color=intervention)) +
  geom_point(shape=1) +
  geom_smooth(method='lm', se=FALSE) +
  facet_wrap(. ~ src, ncol=4) +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     labels = trans_format('log10', math_format(10^.x))) +
  scale_y_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     labels = trans_format('log10', math_format(10^.x))) +
  xlab('Prize') +
  ylab('Indirect ENPV') +
  theme(legend.position = 'top')
```


In summary, we've already established that later interventions must be larger to achieve a private ENPV improvement comparable to earlier interventions.
However, for any given prize size in the plot above, the indirect ENPV (i.e. the cost of that prize for the benefactor) is higher the earlier the intervention is provided.
In summary, for a given prize size, paying early maximizes effect but also unfortunately maximizes benefactor cost.

This analysis is however too simplistic since it ignores that a late phase prize appear cheaper due to fewer go-decisions as a consequence of poorer private ENPV.
<!--However, if we disregard private ENPV improvement differences, then later interventions are cheaper for the benefactor than earlier ones of the same size.-->
Such a simplification is unfortunately unacceptable as the purpose of an indirect intervention is to improve private ENPV to a point where sufficiently many no-decisions are turned into go-decisions.
We must therefore correct for the fact that private ENPV, go-decisions, and indirect ENPV co-vary.

Focusing on only indirect interventions and ignoring direct interventions for a moment, the question is therefore:
Given some target private ENPV improvement, which indirect intervention phase has the lowest indirect ENPV?
Alternatively:

> Which indirect intervention phase has the lowest indirect ENPV, while controlling for private ENPV improvement?

One naive way of avoiding to control for private ENPV improvement is to "flip" the analysis and look at cost per expected output rather than the cost per expected input.
We compute indirect ENPV per output as indirect ENPV (per input) divided by the (technical) probability of reaching market.

```{r, prize-vs-indirect-enpv-in-postgos, echo=FALSE}
finals %>%
  filter(go == TRUE) %>%
  ungroup %>%
  mutate(enpv_ind_per_exit = enpv_ind/tot_prob) %>%
  ggplot(aes(prizes, -enpv_ind_per_exit, color=intervention)) +
  geom_smooth(method='lm', se=FALSE) +
  # TODO: Reintroduce smooth when we have more data again!
  geom_point(shape=1) +
  facet_wrap(. ~ src, ncol=4) +
  scale_x_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     #label = unit_format(unit = '')) +
                     labels = trans_format('log10', math_format(10^.x))) +
  scale_y_continuous(trans = 'log',
                     breaks = c(1 %o% 10^(0:10)),
                     minor_breaks = c(1:9 %o% 10^(0:10)),
                     #label = unit_format(unit = '')) +
                     labels = trans_format('log10', math_format(10^.x))) +
  xlab('Prize') +
  ylab('Indirect ENPV per exit') +
  theme(legend.position = 'top')
```

The problem with this analysis is that when looking at the data per-output, we're not taking the go-rate into consideration.

> A sample of projects reaching go-decisions at some low prize is systematically different from one of projects reaching go-decisions under a high prize.

Read as a "comparison prize", we might therefore conclude that low prizes are efficient (i.e. low cost per output) while high prizes are inefficient (i.e. high cost per output).
This conclusion is evidently however erroneous as brief projects with low cost and low risk require lower prizes for developers to reach a go-decision, while long projects with high cost and high risk require huge prizes for developers to reach a go-decision.

We have therefore only replaced our need to control for private ENPV improvement with the new need to control for go-rate.
In conclusion we must control for either private ENPV improvement (when analyzing indirect ENPV per entry/input) or for go-rate (when analyzing indirect ENPV per exit/output).
<!--Private ENPV and go-rate should be perfectly correlated.-->




## Indirect: efficiency
To estimate an intervention's efficiency we must consider both its effectiveness and its cost.
More specifically we must compute its cost per unit of effect.
We will measure cost as indirect ENPV, and effectiveness as either private ENPV improvement or go-rate.

As previously argued, we will not remove projects that would reach go-decisions irrespectively of the existance of an intervention, as ignoring them would bias the data.
<!--Instead of filtering out the no-go projects and looking at the cost per go-decision, we will -->

We will only look at go-rates lower than `r go_lim_up = 0.99; go_lim_up*100`%.
Since a go-rate higher than 100% is not achievable, any prize size larger than the lowest size that yields a go-rate of 100% will also merely yield 100%.

```{r, go-rate-vs-indirect-enpv, echo=FALSE}
finals %>%
  filter(go_pred_prize < go_lim_up) %>%
  ggplot(aes(go_pred_prize*100, ifelse(enpv_prv_aft >= 0, -enpv_ind, 0), color=intervention)) +
  geom_point(shape=1) +
  geom_smooth(method='loess', se=FALSE, color='black') +
  xlab('Probability of go-decision (%) under prize size') +
  ylab('Indirect ENPV per entry\n(million usd)') +
  scale_y_continuous(label = unit_format(scale = 1e-6, unit = '')) +
  theme(legend.position='none') +
  facet_grid(cols=vars(intervention), rows=vars(src))

finals %>%
  filter(go_pred_prize < go_lim_up) %>%
  filter(enpv_prv_aft >= 0) %>%
  ggplot(aes(go_pred_prize*100, ifelse(enpv_prv_aft >= 0, -enpv_ind, 0), color=intervention)) +
  geom_point(shape=1) +
  geom_smooth(method='loess', se=FALSE, color='black') +
  xlab('Probability of go-decision (%) under prize size') +
  ylab('Indirect ENPV per go-decision\n(million usd)') +
  scale_y_continuous(label = unit_format(scale = 1e-6, unit = '')) +
  theme(legend.position='none') +
  facet_grid(cols=vars(intervention), rows=vars(src))
```

Using local regression (loess) we can see that the interventions again seem to "stack".
This analysis therefore suggests that paying later isn't just more expensive in terms of the "promised prize size", but remains more expensive even when you take attrition rates (i.e. projects terminated for financial or scientific reasons) into account.

```{r, go-rate-vs-indirect-enpv-smooth, echo=FALSE}
a <- data.frame(finals) %>%
  filter(go_pred_prize < go_lim_up) %>%
  filter(enpv_prv_aft >= 0) %>%
  mutate(per = 'per PC go-decision')

b <- data.frame(finals) %>%
  filter(go_pred_prize < go_lim_up) %>%
  mutate(per = 'per PC entry',
         enpv_ind = ifelse(enpv_prv_aft >= 0, enpv_ind, 0))

rbind(a, b) %>%
  ggplot(aes(go_pred_prize*100, -enpv_ind, color=intervention, linetype=per, shape=per)) +
  #geom_point() +
  geom_smooth(method='loess', se=FALSE) +
  scale_linetype_manual(values=c('dotted', 'solid')) +
  facet_wrap(. ~ src) +
  xlab('Probability of go-decision (%) under prize size') +
  ylab('Indirect ENPV (million usd)') +
  scale_y_continuous(label = unit_format(scale = 1e-6, unit = '')) +
  theme(legend.position = 'top', legend.title = element_blank())
```

To tackle the question of whether paying directly or indirectly is preferable, we must compare the above indirect ENPVs to the direct ENPV of simply paying for the project at-cost.
Above, we have however computed the expected cost per pre-clinical entry.
While a perfectly valid statistic it cannot sensibly be compared against the expected cost of direct funding since the output, i.e. the probability of any given entry becoming an exit, actually varies.

When directly funding antibiotics, projects may be terminated at the discretion of the benefactor, but when indirectly funding they may be terminated at the discretion of the project owner.
So to make an "apples to apples" comparison of indirect and direct we would only be able to compare indirect prize sizes that yield go-rates of approximately 100%.
Only then would every input project into pre-clinical stand an equivalent chance of making it through to the market regardless of whether directly or indirectly funded, and only then could we compare the prize per entry.

Given that we however want to explore various go-rates we will hereon move from computing the expected cost per entry to computing the expected cost per exit.
Specifically, the expected, capitalized cost per market approval.
In other words, while we have analyzed the cost per unit of input, we will now move to analyzing the cost per unit of output.

```{r, go-rate-vs-exit, echo=FALSE}
finals %>%
  filter(go_pred_prize < go_lim_up) %>%
  filter(enpv_prv_aft >= 0) %>%
  ggplot(aes(go_pred_prize*100, -enpv_ind/tot_prob, color=intervention)) +
  geom_smooth(method='loess', se=FALSE) +
  facet_wrap(. ~ src) +
  xlab('Probability of go-decision (%) under prize size') +
  ylab('Indirect ENPV per exit (million usd)') +
  scale_y_continuous(label = unit_format(scale = 1e-6, unit = '')) +
  theme(legend.position = 'top')
```

For indirect funding, the cost per output curve is shaped similarly to the cost per input curve.
Importantly however, costs are significantly higher (see y-axis), since we now have to take the technical failure rate into consideration.
Higher go-rates still cause the bottom line, i.e. the cost per output, to be more expensive than lower go-rates.
However, whether our public health system can afford a lower go-rate depends greatly on the rate of discovery, i.e. on the entry rate into pre-clinical, and is a gravely important question outside the scope of this study.
Irrespectively, this figure can be used to estimate how much we will "actually" pay for every new antibiotic when using this form of indirect funding, when choosing to accept a particular go-rate (i.e. chance of any given project reaching a go-decision in pre-clinical).


## Direct: efficiency
There is no need to analyze the effectiveness of direct funding in terms of go-decisions seeing that the core idea of direct funding is to move no-/go-decisions into the hands of the benefactor.
While in reality, the benefactor may strategically choose not to pursue all opportunities we will for the sake of calculation assume that all opportunities are pursued.
Direct funding can thus be thought of as having the same effect (in terms of go-rate) as a go-rate of approximately 100%.
However, to compute the efficiency of direct funding, so that we can compare it to the efficiency of indirect funding, we must identify the cost of direct funding.

<div class="alert alert-danger">
TODO: Actually we need to analyze effectiveness. Think: attrition rate but for time. Go-rate + probability = how many outputs per entry. But go-rate + probability + time = time until output per entry.
</div>

We begin by applying the sampled inefficiencies to our original dataset, and then converting the resulting dataset into the same year-based format used for the analysis of indirect funding.
We assume that public sector inefficiencies have detrimental effects on development costs and times but not probabilities of success.
In other words, we assume that the likelihood of succeeding in turning a hypothetical NCE into a market ready antibiotic is the same for both the public and the private sector (costs and development times aside).
In even other words, we assume that the public sector eventually get to the point that the private do.
But the time it takes the public sector to get there may be longer and during that time they may accumulate a higher cost.

We model this inefficiency as an "efficiency factor" that increases costs and times, while reducing probabilities.
If the efficiency factor, e.g. is 75% then a cost of 10 million will be transformed into a cost of 17.5 million, because 10 \* (1 + 0.75) = 17.5.

```{r, add-inefficiency}
inefficient <- phases %>%
  mutate(cost = cost * (1 + inefficiency),
         time = time * (1 + inefficiency))
inefficient_years <- to_years(inefficient)
inefficient_years <- inefficient_years %>%
  group_by(src, subject, intervention) %>% # TODO: Group by inefficiency?
  arrange(phase, phase_year) %>%
  mutate(time_to = cumsum(time) - time)
```

We then compute the ENPV of directly funding each individual project:

```{r, compute-inefficiency}
inefficient_years <- inefficient_years %>%
  arrange(time_to) %>%
  group_by(src, subject, inefficiency) %>%
  mutate(
         tot_cost = sum(cost),
         tot_prob = prod(prob),
         prob_to = cumprod(prob) / prob, # TODO: Is this correct?
         enpv_dir = cumsum((-cost / ((1 + discount_rate_publ) ^ time_to)) * prob_to),
         ) %>%
  select(-prob_to)
```

and extract the ENPVs of taking each project from pre-clinical to market.

```{r, inefficient-finals}
inefficient_finals <- inefficient_years %>%
  arrange(time_to) %>%
  group_by(src, subject, inefficiency, tot_prob, tot_cost) %>%
  summarise(enpv_dir = tail(enpv_dir, n=1))
```

Finally we can plot the expected cost (in terms of ENPV) per pre-clinical entry of directly funding each project without any financial returns.
When exploring direct funding we're not plotting cost against the go-rate of a prize size but instead aginst different public sector inefficiencies.
When plotting direct ENPV we present it as a positive number that express a cost as opposed to a negative number that express a cashflow.

```{r, inefficiency-vs-direct-enpv-per-entry, echo=FALSE}
inefficient_finals %>%
  ggplot(aes(inefficiency*100, -enpv_dir, color=src)) +
  geom_point(shape=1) +
  geom_smooth(method='lm', se=FALSE, color='black') +
  facet_wrap(. ~ src) +
  xlab('Public inefficiency (%)') +
  ylab('Direct ENPV per entry\n(million usd)') +
  scale_y_continuous(label = unit_format(scale = 1e-6, unit = '')) +
  theme(legend.position='none')
```

Just as with the cost of indirect funding, we can also convert the cost per entry to a cost per exit.

```{r, inefficiency-vs-direct-enpv-per-exit, echo=FALSE}
inefficient_finals %>%
  ggplot(aes(inefficiency*100, -enpv_dir/tot_prob, color=src)) +
  geom_point(shape=1) +
  geom_smooth(method='lm', se=FALSE, color='black') +
  facet_wrap(. ~ src) +
  xlab('Public inefficiency (%)') +
  ylab('Direct ENPV per output\n(million usd)') +
  scale_y_continuous(label = unit_format(scale = 1e-6, unit = '')) +
  theme(legend.position='none')
```


## Comparison
To compare our indirect intervention (non-dilutive prizes) with direct funding, we must compare the efficiency of both approaches.
Since the private sector does not always choose to pursuit all projects, we must be careful with comparing the efficiency of directly funding all projects with that of indirectly funding only those that reach a go-decision.
Since a systematically different set of projects reach private go-decisions under a given prize size, the average cost per output is not really representative of the average cost per output of funding all projects directly (since the private sector pressumably have dropped e.g. some of the most expensive and time-consuming projects).

When comparing the cost per exit of indirect funding with direct funding, we will therefore only compute the cost of directly fund those particular projects that reached a go-decision under the given indirect funding scheme.
It is important to remeber however that even though we are comparing the cost of pursuing the same projects there are still at least two important uncaptured differences between the approaches:
(1) Direct funding would have a different cost (which is reported in the direct-specific analysis section above) and hence go-rate if we chose to pursuit all projects.
(2) Public inefficiencies does not only alert the cost of direct funding but also the amount of time it takes for new antibiotics to reach market.

With these two caveats in mind, we begin by combining the direct dataset and the indirect dataset, and compute the difference in cost for every given go-ratio/inefficiency pair.

<div class="alert alert-danger">
TODO: Actually, not filtering doesn't seem to change anything in the output plot so maybe this isn't logically necessary since we're not looking at go-decisions apart from the go-rate. This needs to be better understood and explained.
</div>

```{r, combine-inefficient-and-efficient}
indirect <- finals %>% ungroup %>%
  select(src, subject, intervention, tot_prob, enpv_ind, go_pred_prize, enpv_prv_aft) %>%
  rename(prob_ind = tot_prob)

direct <- inefficient_finals %>% ungroup %>%
  select(src, subject, tot_prob, enpv_dir, inefficiency) %>%
  rename(prob_dir = tot_prob)

# TODO: Compute efficiencies before merging to avoid renaming
both <- inner_join(indirect, direct, by=c('src', 'subject')) %>%
  mutate(enpv_ind_per_exit = enpv_ind/prob_ind,
         enpv_dir_per_exit = enpv_dir/prob_dir,
         diff = (-enpv_dir_per_exit) - (-enpv_ind_per_exit)) %>%
  filter(go_pred_prize < 0.99)
```


### Cost per output
Then filter out all projects that did not reach a go-decision under the given prize size, and build a linear model that predicts the cost difference between indirect and direct funding from public inefficiency and go-ratio.

```{r, predict-cost-difference}
both_go <- both %>% filter(enpv_prv_aft >= 0)
mod_diff <- glm(diff ~ go_pred_prize * inefficiency * src * intervention, data=both_go)
both_go$diff_pred <- predict(mod_diff, type='response')
```

In the plot below, green indicates that indirect funding (i.e. stimulating private developers) on average is cheaper, white that they are equivalent, and red that direct funding (publicly funding development) on average is cheaper.

```{r, cost-difference-levelplot, echo=FALSE}
both_go %>%
  ggplot(aes(
    round(go_pred_prize*100/5)*5,
    round(inefficiency*100/40)*40,
    fill=diff_pred / 10^9)) +
  scale_fill_gradient2(high='darkgreen', mid='white', low='red', midpoint=0) +
  geom_raster(interpolate=FALSE) +
  facet_grid(rows=vars(src), cols=vars(intervention)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +
  xlab('Prize size yielding probability of go-decision (%)') +
  ylab('Public inefficiency (%)') +
  labs(fill = 'Difference in favor\nof indirect funding\n(billion usd)') +
  theme(legend.position='bottom')
```

These levelplots give an indication of the overall relationship between direct and indirect funding for various levels of go-ratio yielding prize sizes and public inefficiencies.
However, it contains no obvious information on how much cheaper or more expensive a given configuration is.

To allow determining the cost differences under various configurations we can simply plot the two previous efficiency plot side-by-side with aligned y-axes.
It is important to note however that in this plot we cannot compute the cost of directly funding only the projects that receive a go-decision, since to identify which projects reach a go-decision we must pair the inefficiency with a prize size.
Consequently, in the rightmost facet of the plot below we are looking at the cost per output/exit when directly funding every project that enters pre-clinical.
As stated before, this can be thought of as a go-rate of 100%.

Whether the direct or the indirect strategy will yield more projects per time unit is an alltogether different question left unanswered.
To approach that we would have to consider the reduced time efficiency of the direct approach and compare to the reduced go-rate of the indirect approach.

```{r, cost-difference-comparison, echo=FALSE, warning=FALSE}
# TODO: This plot yields lots of errors that I've supressed!
for (curr in sources) {
  sub <- both_go %>%
    filter(src == curr) %>%
    filter(go_pred_prize < go_lim_up)

  p1 <- sub %>%
    ggplot(aes(go_pred_prize*100, -enpv_ind_per_exit, group=intervention, color=intervention)) +
    geom_point(shape=20, alpha=0.5) +
    geom_smooth(method='loess', se=FALSE) +
    geom_line(stat='smooth', method='loess', color='black', alpha=0.2, size=1) +
    facet_wrap(. ~ src) +
    xlab('Prob of go-decision (%) under prize size') +
    ylab('Indirect ENPV per exit\n(million usd)') +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(label = unit_format(scale = 1e-6, unit = ''),
                       breaks = scales::pretty_breaks(n = 8)) +
    theme(legend.position = 'left') +
    ggtitle('Indirect funding')

  yscale <- layer_scales(p1, 1, 1)$y$range$range

  p2 <- inefficient_finals %>%
    filter(src == curr) %>%
    ggplot(aes(inefficiency*100, -enpv_dir/tot_prob)) +
    geom_point(shape=20, color='darkgrey', alpha=0.6) +
    geom_line(stat='smooth', method='lm', color='red', size=1) +
    geom_line(stat='smooth', method='loess', color='black', size=1) +
    facet_wrap(. ~ src) +
    xlab('Public inefficiency (%)') +
    ylab('Direct ENPV per exit\n(million usd)') +
    scale_y_continuous(
      label = unit_format(scale = 1e-6, unit = ''),
      breaks = scales::pretty_breaks(n = 8),
      position='right',
      limits=c(min(yscale), max(yscale))) +
    ggtitle('Direct funding')

  print(ggarrange(p1, p2, ncol=2, nrow=1, widths=c(1, 0.5), common.legend=TRUE))
}
```


### Output probability per input dollar
TODO:

```{r, temp1, echo=FALSE, warning=FALSE}
# TODO: WARNINGS SUPRESSED!

# TODO: These two mutations should be added much earlier.
finals <- finals %>%
  mutate(exit_per_enpv_ind =
         ifelse(enpv_prv_aft >= 0,
                tot_prob / (-enpv_ind),
                0))

inefficient_finals <- inefficient_finals %>%
  mutate(exit_per_enpv_dir = tot_prob / (-enpv_dir))

x <- finals %>%
  filter(exit_per_enpv_ind == Inf)
print(head(data.frame(x)))

finals %>%
 #filter(go_pred_prize < go_lim_up) %>%
 filter(src == curr) %>%
 #ggplot(aes(go_pred_prize*100, exit_per_enpv_ind, color = intervention)) +
 ggplot(aes(prizes, exit_per_enpv_ind, color = intervention)) +
 geom_point(shape=1) +
 geom_smooth(se=FALSE) +
 facet_wrap(. ~ src * intervention) +
 xlab('Prob of go-decision (%) under prize size') +
 ylab('Probability of exit per indirect ENPV') +
 scale_y_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:-12)),
                    minor_breaks = c(1:9 %o% 10^(0:-12))
                    ) +
 scale_x_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:4)) * 10^6,
                    minor_breaks = c(1:9 %o% 10^(0:4)) * 10^6,
                    label = unit_format(scale = 1e-6, unit = '')
                    ) +
 theme(legend.position = 'left',
       axis.text.x = element_text(angle = 90)) +
 ggtitle('Indirect funding')

finals %>%
 #filter(go_pred_prize < go_lim_up) %>%
 filter(src == curr) %>%
 #ggplot(aes(go_pred_prize*100, exit_per_enpv_ind, color = intervention)) +
 ggplot(aes(prizes, exit_per_enpv_ind, color = intervention)) +
 geom_point(shape=1) +
 geom_smooth(se=FALSE) +
 facet_wrap(. ~ src) +
 xlab('Prob of go-decision (%) under prize size') +
 ylab('Probability of exit per indirect ENPV') +
 scale_y_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:-12)),
                    minor_breaks = c(1:9 %o% 10^(0:-12))
                    ) +
 scale_x_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:4)) * 10^6,
                    minor_breaks = c(1:9 %o% 10^(0:4)) * 10^6,
                    label = unit_format(scale = 1e-6, unit = '')
                    ) +
 theme(legend.position = 'left') +
 ggtitle('Indirect funding')

finals %>%
 filter(go_pred_prize < go_lim_up) %>%
 filter(src == curr) %>%
 mutate(exit_per_enpv_ind2 = go_pred_prize * tot_prob / (-enpv_ind)) %>%
 #ggplot(aes(go_pred_prize*100, exit_per_enpv_ind, color = intervention)) +
 ggplot(aes(prizes, exit_per_enpv_ind2, color = intervention)) +
 geom_point(shape=1) +
 geom_smooth(se=FALSE) +
 facet_wrap(. ~ src) +
 ylab('Probability of exit per indirect ENPV (filtered?)') +
 scale_y_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:-12)),
                    minor_breaks = c(1:9 %o% 10^(0:-12))
                    ) +
 scale_x_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:4)) * 10^6,
                    minor_breaks = c(1:9 %o% 10^(0:4)) * 10^6,
                    label = unit_format(scale = 1e-6, unit = '')
                    ) +
 theme(legend.position = 'left') +
 ggtitle('Indirect funding')

finals %>%
 #filter(go_pred_prize < go_lim_up) %>%
 filter(src == curr) %>%
 mutate(exit_per_enpv_ind2 = go_pred_prize * tot_prob / (-enpv_ind)) %>%
 #ggplot(aes(go_pred_prize*100, exit_per_enpv_ind, color = intervention)) +
 ggplot(aes(prizes, exit_per_enpv_ind2, color = intervention)) +
 geom_point(shape=1) +
 geom_smooth(se=FALSE) +
 facet_wrap(. ~ src * intervention) +
 ylab('Probability of exit per indirect ENPV') +
 scale_y_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:-12)),
                    minor_breaks = c(1:9 %o% 10^(0:-12))
                    ) +
 scale_x_continuous(trans='log10',
                    breaks = c(1 %o% 10^(0:4)) * 10^6,
                    minor_breaks = c(1:9 %o% 10^(0:4)) * 10^6,
                    label = unit_format(scale = 1e-6, unit = '')
                    ) +
 theme(legend.position = 'left') +
 ggtitle('Indirect funding')
```

```{r, temp2, echo=FALSE}
for (curr in sources) {
  p1 <- finals %>%
    filter(src == curr) %>%
    filter(go_pred_prize < go_lim_up) %>%
    ggplot(aes(go_pred_prize*100, exit_per_enpv_ind, color = intervention)) +
    geom_smooth(method='loess', se=FALSE) +
    facet_wrap(. ~ src) +
    xlab('Prob of go-decision (%) under prize size') +
    ylab('Indirect ENPV per exit') +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 8)) +
    theme(legend.position = 'left') +
    ggtitle('Indirect funding')

  yscale <- layer_scales(p1, 1, 1)$y$range$range

  p2 <- inefficient_finals %>%
    filter(src == curr) %>%
    ggplot(aes(inefficiency*100, exit_per_enpv_dir, color=src)) +
    #geom_point(shape=1) +
    geom_smooth(method='lm', se=FALSE, color='black') +
    facet_wrap(. ~ src) +
    xlab('Public inefficiency (%)') +
    ylab('Direct ENPV per exit') +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(
      breaks = scales::pretty_breaks(n = 8),
      position='right',
      limits=c(min(yscale), max(yscale))) +
    ggtitle('Direct funding')

  print(ggarrange(p1, p2, ncol=2, nrow=1, widths=c(1, 0.5), common.legend=TRUE))
}
```


# Conclusion
What's the qualitative value-add of stimulating private developers and entrepreneurs that isn't captured in this analysis?

